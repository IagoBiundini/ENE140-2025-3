{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main\n",
        "\n",
        "Essa é a branch \"main\" do grupo. Nela vai haver um arquivo main.py para simplesmente rodar o bot.\n",
        "\n",
        "Seria interessante implementar alguma etapa aqui que verifica se há conexão com a internet caso seja preciso."
      ],
      "metadata": {
        "id": "lOiVT7NDpsKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bot.bot_telegram import BotTelegram\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bot = BotTelegram()\n",
        "    bot.run()"
      ],
      "metadata": {
        "id": "QbmMyEjUprv0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "5fc2da09-315b-41ec-c30f-9b263808b065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2247751531.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbot_telegram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBotTelegram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBotTelegram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# grupo6-bot\n",
        "\n",
        "Branch derivada da \"main\". É aqui onde é feita a criação do bot no Telegram."
      ],
      "metadata": {
        "id": "YF0_51IWayDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ],
      "metadata": {
        "id": "FOfyYBOBXmDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d60e66-f51e-480b-bc87-6011083f957c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (4.15.0)\n",
            "Downloading python_telegram_bot-22.5-py3-none-any.whl (730 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.0/731.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-telegram-bot\n",
            "Successfully installed python-telegram-bot-22.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOKEN_TELEGRAM\"] = \"8226838069:AAHb_-15PLE_Lh9JuWS3BrYMpxpQlefmEtY\""
      ],
      "metadata": {
        "id": "vtbwEuigXH6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-tXHsVKRjA8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters\n",
        "\n",
        "# Configurações básicas para o bot funcionar\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "\n",
        "# Classe main do BotTelegram:\n",
        "class BotTelegram:\n",
        "\n",
        "    # Definição do Token. Ele é único para cada Bot (as instruções para rodá-lo no computador de quem irá utilizar o código devem estar no README):\n",
        "    def __init__(self):\n",
        "        self._token = os.getenv(\"TOKEN_TELEGRAM\")\n",
        "        if not self._token:\n",
        "            raise ValueError(\"Defina a variável de ambiente TOKEN_TELEGRAM (Vide README.md)\")\n",
        "\n",
        "        self._application = ApplicationBuilder().token(self._token).build()\n",
        "        self._handlers() # Já define o _handlers aqui para que mudanças neles sejam mais fáceis de serem feitas\n",
        "\n",
        "    # Definição dos handlers (respostas principais às mensagens do usuário):\n",
        "    def _handlers(self):\n",
        "        self._application.add_handler(CommandHandler(\"start\", self.start)) # Inicia o bot\n",
        "        self._application.add_handler(\n",
        "            MessageHandler(filters.ALL, self.tratar_mensagem) # Trata a mensagem enviada\n",
        "        )\n",
        "\n",
        "    # Mensagem inicial do bot:\n",
        "    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        await update.message.reply_text(\n",
        "            \"Olá! Por favor, envie um áudio ou uma imagem, para que eu realize sua transcrição ou reconhecimento.\"\n",
        "        )\n",
        "\n",
        "    # Handler que trata a mensagem e joga para outras classes específicas para cada tarefa, a depender do que foi enviado:\n",
        "    async def tratar_mensagem(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        if update.message.text:\n",
        "            await self.tratar_texto(update, context)\n",
        "        elif update.message.photo:\n",
        "            await self.tratar_imagem(update, context)\n",
        "        elif update.message.voice or update.message.audio:\n",
        "            await self.tratar_audio(update, context)\n",
        "        else:\n",
        "            await update.message.reply_text(\"Desculpe, a mensagem que você enviou não é de um tipo suportado. Envie apenas imagens ou áudios!\")\n",
        "\n",
        "    # Nessa seção, define a resposta do bot para cada tipo de mensagem enviada:\n",
        "    async def tratar_texto(self, update, context):\n",
        "        await update.message.reply_text(\"Texto recebido com sucesso! No entanto, processar textos está fora do meu escopo.\\nPor favor, envie somente áudios ou imagens ;)\")\n",
        "\n",
        "    async def tratar_imagem(self, update, context):\n",
        "        await update.message.reply_text(\"Imagem recebida com sucesso! Seu processamento está em andamento...\")\n",
        "\n",
        "    async def tratar_audio(self, update, context):\n",
        "        await update.message.reply_text(\"Áudio recebido com sucesso! Seu processamento está em andamento...\")\n",
        "\n",
        "    # Para rodar o código do bot:\n",
        "    def run(self):\n",
        "        self._application.run_polling()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# grupo6-img\n",
        "\n",
        "Essa branch é derivada da \"grupo6\". É aqui onde fica a subclasse para reconhecimento de imagens."
      ],
      "metadata": {
        "id": "ChlUOqoka9RP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKOcxAXibHdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# grupo6-audio\n",
        "\n",
        "Essa branch é derivada da \"grupo6\". É aqui onde fica a subclasse para transcrição de áudios. Coloquei para ele reconhecer tanto áudios enviados pelo Telegram quanto arquivos externos."
      ],
      "metadata": {
        "id": "1A2Xo-A6bH3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install vosk"
      ],
      "metadata": {
        "id": "IAn1qDlvbLeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5d376c-19c9-4b9f-f28b-9e519827971f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from vosk) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vosk) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->vosk) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vosk) (2025.11.12)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=708fb16f30eab8d14a965e204245bbe6269541ac8e01bdbf479998224c5db2f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/75/5b/e1d5c3756631e4bda806f6cc9640153b39484bb6f7b0b8def3\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixa package para conhecimento de voz em Português-BR\n",
        "!wget https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip\n",
        "\n",
        "# Descompacta o arquivo .zip\n",
        "!unzip vosk-model-small-pt-0.3.zip\n"
      ],
      "metadata": {
        "id": "GJKB6PzhhZEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ef7580-b694-408c-9292-9a5ad2a21818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-08 18:44:37--  https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32453112 (31M) [application/zip]\n",
            "Saving to: ‘vosk-model-small-pt-0.3.zip’\n",
            "\n",
            "vosk-model-small-pt 100%[===================>]  30.95M  9.48MB/s    in 3.3s    \n",
            "\n",
            "2026-01-08 18:44:41 (9.48 MB/s) - ‘vosk-model-small-pt-0.3.zip’ saved [32453112/32453112]\n",
            "\n",
            "Archive:  vosk-model-small-pt-0.3.zip\n",
            "   creating: vosk-model-small-pt-0.3/\n",
            " extracting: vosk-model-small-pt-0.3/README  \n",
            "  inflating: vosk-model-small-pt-0.3/final.mdl  \n",
            "  inflating: vosk-model-small-pt-0.3/disambig_tid.int  \n",
            "  inflating: vosk-model-small-pt-0.3/phones.txt  \n",
            "  inflating: vosk-model-small-pt-0.3/Gr.fst  \n",
            "   creating: vosk-model-small-pt-0.3/ivector/\n",
            "  inflating: vosk-model-small-pt-0.3/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-small-pt-0.3/ivector/online_cmvn.conf  \n",
            "  inflating: vosk-model-small-pt-0.3/ivector/splice.conf  \n",
            "  inflating: vosk-model-small-pt-0.3/ivector/final.ie  \n",
            "  inflating: vosk-model-small-pt-0.3/ivector/final.dubm  \n",
            "  inflating: vosk-model-small-pt-0.3/ivector/final.mat  \n",
            "  inflating: vosk-model-small-pt-0.3/HCLr.fst  \n",
            "  inflating: vosk-model-small-pt-0.3/mfcc.conf  \n",
            "  inflating: vosk-model-small-pt-0.3/word_boundary.int  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import tempfile\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "class BotAudio(BotTelegram):\n",
        "\n",
        "    async def tratar_audio(self, update, context): # Aqui entra o polimorfismo na classe filha\n",
        "\n",
        "        # Identifica se é áudio do Telegram ou externo:\n",
        "        if update.message.voice: # Telegram\n",
        "          file = await update.message.voice.get_file()\n",
        "          suffix = \".ogg\"\n",
        "\n",
        "        elif update.message.audio: # Externo\n",
        "          mime = update.message.audio.mime_type # Pega o tipo do arquivo\n",
        "          if not mime or not mime.startswith(\"audio/\"): # Se o arquivo não é áudio, rejeita\n",
        "            await update.message.reply_text(\"Hmm... Parece que o arquivo que você enviou não é um arquivo de áudio válido. Tente novamente!\")\n",
        "            return\n",
        "\n",
        "          file = await update.message.audio.get_file()\n",
        "          suffix = os.path.splitext(update.message.audio.file_name)[1] # Pega formato do arquivo\n",
        "\n",
        "        else:\n",
        "          await update.message.reply_text(\"Muito bem! Envie uma mensagem de voz ou um arquivo de áudio para que eu os transcreva!\")\n",
        "          return\n",
        "\n",
        "        # Salva temporariamente para o processamento:\n",
        "        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=suffix).name\n",
        "        await file.download_to_drive(temp_audio)\n",
        "\n",
        "        # Converte para WAV padrão:\n",
        "        wav_path = temp_audio.replace(suffix, \".wav\")\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", # O FFMPEG é um \"programa\" que realiza conversões de arquivos\n",
        "            \"-i\", temp_audio, # Define arquivo de entrada\n",
        "            \"-ar\", \"16000\", # Taxa de amostragem do áudio (16kHz)\n",
        "            \"-ac\", \"1\", # Define áudio como mono\n",
        "            wav_path,\n",
        "            \"-y\" # Muda o formato\n",
        "        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Abre arquivo WAV convertido:\n",
        "        wf = wave.open(wav_path, \"rb\")\n",
        "\n",
        "        # Estabelece o modelo do Vosk PT-BR (aqui ele chama o mais leve, podemos trocar depois):\n",
        "        model = Model(\"vosk-model-small-pt-0.3\")\n",
        "        rec = KaldiRecognizer(model, wf.getframerate())\n",
        "\n",
        "        # Processa o áudio:\n",
        "        while True:\n",
        "            data = wf.readframes(4000) # Processa 4k frames por vez\n",
        "            if len(data) == 0: # Espera áudio terminar\n",
        "                break\n",
        "            rec.AcceptWaveform(data) # Envia para processamento\n",
        "\n",
        "        texto = json.loads(rec.FinalResult()).get(\"text\", \"\") # Extrai o texto do Vosk\n",
        "\n",
        "        # Verifica se o áudio é vazio; se não, transcreve:\n",
        "        if not texto.strip():\n",
        "          await update.message.reply_text(\"Poxa, seu áudio está vazio :(\\nQue tal me enviar algo com conteúdo para que eu possa transcrevê-lo?\")\n",
        "        else:\n",
        "          await update.message.reply_text(f\"Muito bem! Aqui está o seu áudio transcrito:\\n{texto}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wuNk5f5QhoEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
